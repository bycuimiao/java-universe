1、System.currentTimeMills()性能问题  
https://www.jianshu.com/p/d2039190b1cb  
 http://pzemtsov.github.io/2017/07/23/the-slow-currenttimemillis.html
 
2、
「 青南: 请教大家一个问题：

内存只有1GB，又n行内容，其中有非常多的内容重复。这N行内容有10GB，重复内容有3GB。

请问应该如何去重？

如果电脑内存足够，我可以维护一个集合，把这N行内容一行一行判断在不在集合在，如果在，就丢弃。如果不在，就加入集合。

但是这样一来，这个集合的大小会超过6GB。而我内存只有1GB。请问有什么好办法处理吗？ 」
- - - - - - - - - - - - - - -
我理解这道题是想要1G内存做处理，但硬盘其实是足够的。
如果只有1G内存的话，我们可以考虑牺牲时间换取空间的办法。
比如用大顶堆排序，慢慢读取整个文件，并在同时剔除重复数据。1G内存慢的时候，这1G的内存的有序数据就没有重复了。这时将数据写入硬盘，对剩下的数据做递归处理即可。
@青南

    1、大顶堆   
    2、布隆过滤器  
    3、hash文件拆分合并  

3、BigDecimal注释 
In the case of divide, the exact quotient could have an infinitely long decimal expansion
在除法的情况下，精确的商可以有无限长的十进制扩展